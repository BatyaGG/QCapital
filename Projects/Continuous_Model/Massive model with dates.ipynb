{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import random\n",
    "import math\n",
    "import pickle\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "# from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# from skopt import gp_minimize\n",
    "# from skopt.space import Integer, Real, Categorical\n",
    "# from skopt.utils import use_named_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "read_csv() got an unexpected keyword argument 'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-db850e65007c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# volume = pd.read_parquet('rus_volume_201120.parquet')#.iloc[:,:10]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmarket\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"market.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: read_csv() got an unexpected keyword argument 'index'"
     ]
    }
   ],
   "source": [
    "# close = pd.read_parquet('rus_close_201120.parquet')#.iloc[:,:10]\n",
    "# volume = pd.read_parquet('rus_volume_201120.parquet')#.iloc[:,:10]\n",
    "\n",
    "market = pd.read_csv(\"market.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>vix</th>\n",
       "      <th>spy</th>\n",
       "      <th>spyv</th>\n",
       "      <th>rate10y</th>\n",
       "      <th>rate3m</th>\n",
       "      <th>dxy</th>\n",
       "      <th>oil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02.01.2002</td>\n",
       "      <td>22.71</td>\n",
       "      <td>115.53</td>\n",
       "      <td>18652200</td>\n",
       "      <td>5.160</td>\n",
       "      <td>1.736</td>\n",
       "      <td>115.790</td>\n",
       "      <td>21.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03.01.2002</td>\n",
       "      <td>21.34</td>\n",
       "      <td>116.84</td>\n",
       "      <td>15743100</td>\n",
       "      <td>5.111</td>\n",
       "      <td>1.716</td>\n",
       "      <td>116.110</td>\n",
       "      <td>20.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04.01.2002</td>\n",
       "      <td>20.45</td>\n",
       "      <td>117.62</td>\n",
       "      <td>20140700</td>\n",
       "      <td>5.128</td>\n",
       "      <td>1.715</td>\n",
       "      <td>116.330</td>\n",
       "      <td>21.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>07.01.2002</td>\n",
       "      <td>21.94</td>\n",
       "      <td>116.79</td>\n",
       "      <td>13106500</td>\n",
       "      <td>5.049</td>\n",
       "      <td>1.685</td>\n",
       "      <td>116.330</td>\n",
       "      <td>21.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08.01.2002</td>\n",
       "      <td>21.83</td>\n",
       "      <td>116.52</td>\n",
       "      <td>12687200</td>\n",
       "      <td>5.080</td>\n",
       "      <td>1.675</td>\n",
       "      <td>116.830</td>\n",
       "      <td>21.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4808</th>\n",
       "      <td>08.02.2021</td>\n",
       "      <td>21.24</td>\n",
       "      <td>390.51</td>\n",
       "      <td>38365185</td>\n",
       "      <td>1.171</td>\n",
       "      <td>0.030</td>\n",
       "      <td>90.934</td>\n",
       "      <td>57.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4809</th>\n",
       "      <td>09.02.2021</td>\n",
       "      <td>21.63</td>\n",
       "      <td>390.25</td>\n",
       "      <td>35551059</td>\n",
       "      <td>1.159</td>\n",
       "      <td>0.030</td>\n",
       "      <td>90.439</td>\n",
       "      <td>58.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4810</th>\n",
       "      <td>10.02.2021</td>\n",
       "      <td>21.99</td>\n",
       "      <td>390.08</td>\n",
       "      <td>59154370</td>\n",
       "      <td>1.123</td>\n",
       "      <td>0.041</td>\n",
       "      <td>90.371</td>\n",
       "      <td>58.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4811</th>\n",
       "      <td>11.02.2021</td>\n",
       "      <td>21.25</td>\n",
       "      <td>390.71</td>\n",
       "      <td>42913288</td>\n",
       "      <td>1.166</td>\n",
       "      <td>0.038</td>\n",
       "      <td>90.417</td>\n",
       "      <td>58.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4812</th>\n",
       "      <td>12.02.2021</td>\n",
       "      <td>19.97</td>\n",
       "      <td>392.64</td>\n",
       "      <td>50593270</td>\n",
       "      <td>1.211</td>\n",
       "      <td>0.039</td>\n",
       "      <td>90.480</td>\n",
       "      <td>59.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4813 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date    vix     spy      spyv  rate10y  rate3m      dxy    oil\n",
       "0     02.01.2002  22.71  115.53  18652200    5.160   1.736  115.790  21.01\n",
       "1     03.01.2002  21.34  116.84  15743100    5.111   1.716  116.110  20.37\n",
       "2     04.01.2002  20.45  117.62  20140700    5.128   1.715  116.330  21.62\n",
       "3     07.01.2002  21.94  116.79  13106500    5.049   1.685  116.330  21.48\n",
       "4     08.01.2002  21.83  116.52  12687200    5.080   1.675  116.830  21.25\n",
       "...          ...    ...     ...       ...      ...     ...      ...    ...\n",
       "4808  08.02.2021  21.24  390.51  38365185    1.171   0.030   90.934  57.97\n",
       "4809  09.02.2021  21.63  390.25  35551059    1.159   0.030   90.439  58.36\n",
       "4810  10.02.2021  21.99  390.08  59154370    1.123   0.041   90.371  58.68\n",
       "4811  11.02.2021  21.25  390.71  42913288    1.166   0.038   90.417  58.24\n",
       "4812  12.02.2021  19.97  392.64  50593270    1.211   0.039   90.480  59.47\n",
       "\n",
       "[4813 rows x 8 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4632, 14106)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "close.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "market = market.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'year'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-8d97cb2cb69a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mmarket\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dt'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmarket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mmarket\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dt'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmarket\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0mmarket\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'spyval'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmarket\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'spy'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmarket\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'spyv'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m1000000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4106\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4107\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4108\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-8d97cb2cb69a>\u001b[0m in \u001b[0;36myear_start\u001b[0;34m(date)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mMakes\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0maware\u001b[0m \u001b[0mof\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \"\"\"\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myear\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mbase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m366\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'year'"
     ]
    }
   ],
   "source": [
    "def year_start(date):\n",
    "    \"\"\"\n",
    "    Makes the model aware of current date\n",
    "    \"\"\"\n",
    "    if date.year % 4 == 0:\n",
    "        base = 366\n",
    "    else:\n",
    "        base = 365\n",
    "        \n",
    "    ystart = pd.to_datetime(str(date.year) + '-01-01')\n",
    "    return (date - ystart).days / base\n",
    "\n",
    "\n",
    "def get_tick_df(x, split=pd.to_datetime('2017-01-01')):\n",
    "    \"\"\"\n",
    "    Combines information for a ticker from 'close' and 'volume' dataframes into one,\n",
    "    Calculates 'valtr' column - 'value traded',\n",
    "    Splits data into master 'train' and 'test' parts\n",
    "    \n",
    "    x - column index for the respective column date\n",
    "    split - date to split into 'test' and 'train' parts\n",
    "    \"\"\"\n",
    "    tick_df = close.iloc[:,x:x+2]\n",
    "    tick = tick_df.columns[1]\n",
    "    tick_df['volume'] = volume[tick]\n",
    "    tick_df.columns = ['date', tick, 'volume']\n",
    "    tick_df = tick_df.set_index('date').dropna()\n",
    "    tick_df['valtr'] = tick_df[tick] * tick_df['volume'] / 1000000\n",
    "    train = tick_df.loc[:split]\n",
    "    test = tick_df.copy()\n",
    "    \n",
    "    return train, test\n",
    "\n",
    "market['dt'] = market.index\n",
    "market['dt'] = market['dt'].apply(year_start)\n",
    "market['spyval'] = market['spy'] * market['spyv'] / 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "807aa38141654c97bcc95577dffcaf90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7053 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(Timestamp('2016-12-30 00:00:00'), Timestamp('2002-01-02 00:00:00'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 0\n",
    "\n",
    "train_df = {}\n",
    "test_df = {}\n",
    "split = pd.to_datetime('2017-01-01')\n",
    "\n",
    "for _ in tqdm_notebook(range(int(close.shape[1]/2))):\n",
    "    \n",
    "    tick = close.iloc[:,x+1].name\n",
    "    if close[tick].dropna().shape[0] == 0:\n",
    "        # some are empty, these are ignored\n",
    "        x+=2\n",
    "        continue\n",
    "    else:\n",
    "        train_df[tick], test_df[tick] = get_tick_df(x, split=split)\n",
    "        x+=2\n",
    "\n",
    "train_market = market.loc[:split]\n",
    "test_market = market.copy()\n",
    "\n",
    "train_market.index[-1], test_market.index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_cv_error(cv_periods, verbose=True):\n",
    "    \"\"\"\n",
    "    Checks for look-ahead biases and other errors in cv periods,\n",
    "    reports data if required so or if silent - raises exceptions\n",
    "    \"\"\"\n",
    "    sub_start = cv_periods['sub_start']\n",
    "    sub_end = cv_periods['sub_end']\n",
    "    val_start = cv_periods['val_start']\n",
    "    val_end = cv_periods['val_end']\n",
    "#     test_start = cv_periods['test_start']\n",
    "#     test_end = cv_periods['test_end']\n",
    "    \n",
    "    if verbose:\n",
    "        if sub_start > sub_end:\n",
    "            print(\"Training sample dates error\")\n",
    "\n",
    "        if sub_end > val_start:\n",
    "            print(\"Validation starts before training ends!\")\n",
    "\n",
    "        if val_start > val_end:\n",
    "            print(\"Validation sample dates error\")\n",
    "\n",
    "#         if val_end > test_start:\n",
    "#             print(\"Testing starts before validation ends!\")\n",
    "\n",
    "#         if test_start > test_end:\n",
    "#             print(\"Testing sample dates error\")\n",
    "\n",
    "        print(\"Training starts at\", sub_start, \"Training sample size is\", (sub_end - sub_start).days, \n",
    "              \"\\nValidation starts at\", val_start, \"Validation sample size is\", (val_end - val_start).days,\n",
    "#              \"\\nTesting starts at\", test_start, \"Testing sample size is\", (test_end - test_start).days,\n",
    "              \"\\nNumber of days purged between training and validation is\", (val_start - sub_end).days)\n",
    "\n",
    "#              \"\\nNumber of days purged between validation and testing is\", (test_start - val_end).days\n",
    "    \n",
    "    else:\n",
    "        if sub_start > sub_end:\n",
    "            raise Exception(\"Training sample dates error\")\n",
    "\n",
    "        if sub_end > val_start:\n",
    "            raise Exception(\"Validation starts before training ends!\")\n",
    "\n",
    "        if val_start > val_end:\n",
    "            raise Exception(\"Validation sample dates error\")\n",
    "\n",
    "#         if val_end > test_start:\n",
    "#             raise Exception(\"Testing starts before validation ends!\")\n",
    "\n",
    "#         if test_start > test_end:\n",
    "#             raise Exception(\"Testing sample dates error\")\n",
    "        \n",
    "    pass\n",
    "\n",
    "def shift_cv(cv_periods, shift=6, drag=False):\n",
    "    \"\"\"\n",
    "    Shifts cross-validation periods by a set number of months\n",
    "    \"\"\" \n",
    "    \n",
    "    new_periods = {}\n",
    "    for k, v in cv_periods.items():\n",
    "        if (k == 'sub_start') and (drag == False):\n",
    "            new_periods[k] = v\n",
    "        else:\n",
    "            new_periods[k] = (v + np.timedelta64(shift, 'M')).round('d')\n",
    "    \n",
    "    return new_periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_to_one(series, log=True):\n",
    "    \"\"\"\n",
    "    Scales data from 0 to 1 while not looking ahead because of cummin/cummax methods.\n",
    "    If log=True, first takes np.log of the series\n",
    "    \"\"\"\n",
    "    if log:\n",
    "        return (np.log(series) - np.log(series).cummin()) / (np.log(series).cummax() - np.log(series).cummin() )\n",
    "    else:\n",
    "        return (series - series.cummin()) / (series.cummax() - series.cummin() )\n",
    "    \n",
    "def prod_return(valdf, compress=0.5, sharpe=True, com=0.002, penalize=0.1):\n",
    "    \n",
    "    if 'predy' not in valdf.columns:\n",
    "        print(\"No 'predy' column found!\")\n",
    "        return 0\n",
    "    elif 'fwd' not in valdf.columns:\n",
    "        print(\"No 'fwd' column found!\")\n",
    "        return 0\n",
    "    elif (compress != None) and ( compress <= 0):\n",
    "        print(\"'compress' input must be >0!\")\n",
    "        return 0\n",
    "    \n",
    "    else:\n",
    "        if compress != None:\n",
    "            valdf['fwd'] = np.where( valdf['fwd'] > 0.5, 0.5, valdf['fwd'] )\n",
    "        \n",
    "        valdf['pred_return'] = 1 + valdf['predy'] * (valdf['fwd'] - com)\n",
    "        \n",
    "        if valdf.predy.sum() >= 1:\n",
    "            prod_return = valdf['pred_return'].prod()**(1.0/len(valdf[valdf.predy == 1])) - 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "        if penalize:\n",
    "            if 'testy' not in valdf.columns:\n",
    "                print(\"No 'testy' column found!\")\n",
    "                return 0\n",
    "            \n",
    "            ratio = valdf['predy'].mean()/valdf['testy'].mean()\n",
    "            if ratio < penalize:\n",
    "                prod_return = prod_return * ratio / penalize\n",
    "        \n",
    "        if sharpe:\n",
    "            \n",
    "            return (prod_return / valdf[valdf.predy == 1]['fwd'].std())\n",
    "            \n",
    "        else:\n",
    "            return prod_return\n",
    "\n",
    "def preproc_mkt(mkt_df, price_lags=[1,5,20,250], vol_lags=[2,10]):\n",
    "    \n",
    "    \"\"\"\n",
    "    Prepares data for market dataframe. \n",
    "    Creates delta features for every price_lags unit for spy price, 10year rate, 3month rate and oil price.\n",
    "    Creates rolling average features for 1 and every vol_lags unit for vix, dollar index and spy volume. \n",
    "    \n",
    "    returns clean market dataframe and columns of the dataframe\n",
    "    Attention! returing dataframe contains a non-feature column 'spyv', used for further relative feature creation \n",
    "    \"\"\"\n",
    "    \n",
    "    for lag in price_lags:\n",
    "        ret_name = 'spy' + str(lag)\n",
    "        mkt_df[ret_name] = mkt_df['spy']/mkt_df['spy'].shift(lag)-1\n",
    "        mkt_df[ret_name] = zero_to_one(mkt_df[ret_name], log=False)\n",
    "\n",
    "        ret_name = '10y' + str(lag)\n",
    "        mkt_df[ret_name] = mkt_df['rate10y']/mkt_df['rate10y'].shift(lag)-1\n",
    "        mkt_df[ret_name] = zero_to_one(mkt_df[ret_name], log=False)\n",
    "\n",
    "        ret_name = '3m' + str(lag)\n",
    "        mkt_df[ret_name] = mkt_df['rate3m']/mkt_df['rate3m'].shift(lag)-1\n",
    "        mkt_df[ret_name] = zero_to_one(mkt_df[ret_name], log=False)\n",
    "\n",
    "        ret_name = 'oil' + str(lag)\n",
    "        mkt_df[ret_name] = mkt_df['oil']/mkt_df['oil'].shift(lag)-1\n",
    "        mkt_df[ret_name] = zero_to_one(mkt_df[ret_name], log=False)\n",
    "\n",
    "\n",
    "    mkt_df['spyvol'] = zero_to_one(mkt_df['spyv'], log=True)\n",
    "    \n",
    "    mkt_df['dxy'] = zero_to_one(mkt_df['dxy'], log=False)\n",
    "    \n",
    "    mkt_df['s_vix'] = zero_to_one(mkt_df['vix'], log=True)\n",
    "\n",
    "    for lag in vol_lags:\n",
    "        mkt_df['spyvol' + str(lag)] = mkt_df['spyvol'].rolling(lag).mean()\n",
    "        mkt_df['dxy' + str(lag)] = mkt_df['dxy'].rolling(lag).mean()\n",
    "        mkt_df['s_vix' + str(lag)] = mkt_df['s_vix'].rolling(lag).mean()\n",
    "\n",
    "    junk_cols = ['vix', 'spy', 'spyv', 'rate10y', 'rate3m', 'oil']\n",
    "\n",
    "    mkt_df = mkt_df.drop(columns=junk_cols)\n",
    "#    print(mkt_df.shape)\n",
    "    return mkt_df, mkt_df.columns\n",
    "\n",
    "def preproc_tick(tick, fulldf, market_df, market_cols, fwd=5, \n",
    "                 cut_first=150, price_lags=[1,2,5,10,20,50,100,250], vol_lags=[2,5,10,20]):\n",
    "    \"\"\"\n",
    "    Prepares data for a ticker dataframe. \n",
    "    Creates delta features for every price_lags unit for close price.\n",
    "    Creates rolling average features for 1 and every vol_lags unit for volatility and value traded. \n",
    "    Cuts first 150 days, because they are too noisy usually due to cummax/cummin methods\n",
    "    \n",
    "    Parameters:\n",
    "        tick - ticker used\n",
    "        fulldf - dictionary with all tickers that is limited by cv_periods\n",
    "        market_df - output of preproc_mkt function\n",
    "        market_cols - output of preproc_mkt function\n",
    "        fwd - forecasting period in days\n",
    "    \n",
    "    returns clean ticker dataframe \n",
    "    \"\"\"\n",
    "    \n",
    "    idf = fulldf[tick]\n",
    "    idf['fwd'] = idf[tick].shift(-fwd) / idf[tick] - 1\n",
    "    idf['ycol'] = np.where( idf['fwd'] >= 0.02, 1, 0 )\n",
    "    \n",
    "    idf[market_cols] = market_df\n",
    "    \n",
    "    for lag in price_lags:\n",
    "        ret_name = 'ret' + str(lag)\n",
    "        idf[ret_name] = idf[tick]/idf[tick].shift(lag)-1\n",
    "        idf[ret_name] = zero_to_one(idf[ret_name], log=False)\n",
    "\n",
    "    idf['relvol'] = np.log(idf['valtr']) / np.log(idf['spyval'])\n",
    "#    idf['relvol'] = zero_to_one(idf['relvol'], log=False)\n",
    "    idf['vol'] = zero_to_one(idf['volume'], log=True)\n",
    "    idf['val'] = zero_to_one(idf['valtr'], log=True)\n",
    "\n",
    "    for lag in vol_lags:\n",
    "        idf['vol' + str(lag)] = idf['vol'].rolling(lag).mean()\n",
    "        idf['val' + str(lag)] = idf['val'].rolling(lag).mean()\n",
    "        idf['rel_val' + str(lag)] = idf['relvol'].rolling(lag).mean()\n",
    "    \n",
    "    idf['tick'] = tick\n",
    "    \n",
    "    junk_cols = [tick, 'volume', 'valtr', 'spyval']\n",
    "    \n",
    "#     print(tick, idf.drop(columns=junk_cols).iloc[cut_first:].dropna().shape, \n",
    "#           idf.drop(columns=junk_cols).iloc[cut_first:].isna().sum(), \n",
    "#           '\\n', idf.drop(columns=junk_cols).iloc[cut_first:], '\\n\\n\\n\\n')\n",
    "\n",
    "#    print(idf.drop(columns=junk_cols).iloc[cut_first:].dropna().shape)\n",
    "    return idf.drop(columns=junk_cols).iloc[cut_first:].dropna()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_tvt(train_df, train_market, cv_periods, settings=None, state_size=False):\n",
    "    \"\"\"\n",
    "    creates train, validation and test subsamples for the given cv_periods\n",
    "    Parameters:\n",
    "        train_df - full training dictionary of all tickers\n",
    "        train_df - full market training dictionary\n",
    "        cv_periods - current limits on dates\n",
    "    \"\"\"\n",
    "    sub_df = {}\n",
    "    val_df = {}\n",
    "#     tst_df = {}\n",
    "\n",
    "    for k, v in train_df.items():\n",
    "\n",
    "        sub_df[k] = v.loc[cv_periods['sub_start']:cv_periods['sub_end']]\n",
    "        val_df[k] = v.loc[cv_periods['sub_start']:cv_periods['val_end']]\n",
    "#         tst_df[k] = v.loc[cv_periods['sub_start']:cv_periods['test_end']]\n",
    "\n",
    "    market_sub = train_market.loc[cv_periods['sub_start']:cv_periods['sub_end']].copy()\n",
    "    market_val = train_market.loc[cv_periods['sub_start']:cv_periods['val_end']].copy()\n",
    "#     market_tst = train_market.loc[cv_periods['sub_start']:cv_periods['test_end']].copy()\n",
    "    \n",
    "    if state_size:\n",
    "        print(market_sub.shape, market_sub.isna().sum())\n",
    "    \n",
    "    if settings == None:\n",
    "        market_sub, _ = preproc_mkt(market_sub)\n",
    "        market_val, market_cols = preproc_mkt(market_val)\n",
    "#         market_tst, market_cols = preproc_mkt(market_tst)\n",
    "    else:\n",
    "        market_sub, _ = preproc_mkt(market_sub, **settings['preproc_mkt'])\n",
    "        market_val, market_cols = preproc_mkt(market_val, **settings['preproc_mkt'])\n",
    "#         market_tst, market_cols = preproc_mkt(market_tst, **settings['preproc_mkt'])        \n",
    "\n",
    "    \n",
    "    train = {}\n",
    "    val = {}\n",
    "#     tst = {}\n",
    "    \n",
    "    if settings == None:\n",
    "        for tick in tqdm_notebook(sub_df.copy().keys()):\n",
    "            train[tick] = preproc_tick(tick, sub_df, market_sub, market_cols)\n",
    "            val[tick] = preproc_tick(tick, val_df, market_val, market_cols).loc[cv_periods['val_start']:]\n",
    "#             tst[tick] = preproc_tick(tick, tst_df, market_tst, market_cols).loc[cv_periods['test_start']:]\n",
    "    else:\n",
    "        for tick in sub_df.copy().keys():\n",
    "            train[tick] = preproc_tick(tick, sub_df, market_sub, market_cols, **settings['preproc_tick'])\n",
    "            val[tick] = preproc_tick(tick, val_df, market_val, market_cols, \\\n",
    "                                     **settings['preproc_tick']).loc[cv_periods['val_start']:]\n",
    "#             tst[tick] = preproc_tick(tick, tst_df, market_tst, market_cols, \\\n",
    "#                                      **settings['preproc_tick']).loc[cv_periods['test_start']:]        \n",
    "    \n",
    "    train = pd.concat( train.values() ).sort_index()\n",
    "    train['tick date'] = train['tick'] + ':' + train.index.astype(str)\n",
    "    train = train.set_index('tick date').drop(columns=['tick'])\n",
    "    \n",
    "    val = pd.concat( val.values() ).sort_index()\n",
    "    val['tick date'] = val['tick'] + ':' + val.index.astype(str)\n",
    "    val = val.set_index('tick date').drop(columns=['tick'])\n",
    "    \n",
    "#     tst = pd.concat( tst.values() ).sort_index()\n",
    "#     tst['tick date'] = tst['tick'] + ':' + tst.index.astype(str)\n",
    "#     tst = tst.set_index('tick date').drop(columns=['tick'])\n",
    "    \n",
    "    if state_size:\n",
    "        print(train.shape)\n",
    "    \n",
    "    return train, val #, tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_step(train_df, train_market, cv_periods, settings=None):\n",
    "    \"\"\"\n",
    "    Calculates validation score, provides with testing dataframe and current model\n",
    "    for current cross-validation step.\n",
    "    Parameters:\n",
    "        train_df - full training dictionary of all tickers\n",
    "        train_df - full market training dictionary\n",
    "        cv_periods - current limits on dates\n",
    "        settings - settings to pass on    \n",
    "    \"\"\"\n",
    "    \n",
    "    if settings == None:\n",
    "        genmodel = LGBMClassifier\n",
    "        check_cv_error(cv_periods, verbose=False)\n",
    "        model = genmodel(random_state=1, n_jobs=-1)\n",
    "        train, val = prepare_tvt(train_df, train_market, cv_periods)\n",
    "    else:\n",
    "        genmodel = settings['genmodel']\n",
    "        check_cv_error(cv_periods, verbose=settings['verbose'])\n",
    "        train, val = prepare_tvt(train_df, train_market, cv_periods, settings)    \n",
    "        \n",
    "        model = genmodel(random_state=1, n_jobs=-1, **settings['model_settings'])\n",
    "        \n",
    "    \n",
    "    \n",
    "    train_X = train.drop(columns = ['ycol', 'fwd'])\n",
    "    train_y = train['ycol']\n",
    "    val_X = val.drop(columns = ['ycol', 'fwd'])\n",
    "    val_y = val['ycol']\n",
    "    \n",
    "    try:\n",
    "        model.fit(train_X, train_y)\n",
    "    except:\n",
    "        train, val = prepare_tvt(train_df, train_market, cv_periods, settings, state_size=True)\n",
    "        print(train_X.shape, train.shape)\n",
    "        print(settings['model_settings'])\n",
    "        print(cv_periods)\n",
    "        \n",
    "        raise Exception('Error')\n",
    "    \n",
    "    if settings == None:\n",
    "        val_X['proby'] = model.predict_proba(val_X)[:,1]\n",
    "        val_X['predy'] = np.where(val_X['proby'] > 0.5, 1, 0)\n",
    "    else:\n",
    "        val_X['proby'] = model.predict_proba(val_X)[:,1]\n",
    "        val_X['predy'] = np.where(val_X['proby'] > settings['threshold'], 1, 0)\n",
    "   \n",
    "    val_X['fwd'] = val['fwd']\n",
    "        \n",
    "    val_X['testy'] = val_y\n",
    "    #val_score = val_X[['predy', 'testy']].corr().iloc[0][1]\n",
    "    \n",
    "    return val_X[['testy','predy','proby','fwd']], model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9ae5d26ad3b455db117be54b9152135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6949 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv_periods = {\n",
    "        'sub_start': pd.to_datetime('2002-07-01'),\n",
    "        'sub_end': pd.to_datetime('2005-07-01'),\n",
    "        'val_start': pd.to_datetime('2005-08-01'),\n",
    "        'val_end': pd.to_datetime('2006-01-01'),\n",
    "#         'test_start': pd.to_datetime('2006-02-01'),\n",
    "#         'test_end':pd.to_datetime('2006-07-01')\n",
    "    }\n",
    "\n",
    "val, model = cv_step(train_df, train_market, cv_periods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "search_space = [\n",
    "    \n",
    "    Categorical(['gbdt', 'dart', 'goss', 'rf'], name='boosting_type'),\n",
    "    Integer(2, 4096, name='num_leaves'),\n",
    "    Real(0.0001, 0.3, prior='log-uniform', name='learning_rate'),\n",
    "    Integer(2, 1000, name='n_estimators'),\n",
    "    Real(0.01, 0.999, name='subsample'),\n",
    "    Real(0.0001, 0.3, prior='log-uniform', name='min_child_weight'),\n",
    "    Integer(5, 1000, name='min_child_samples'),\n",
    "    Real(0.2, 0.999, prior='uniform', name='feature_fraction'),\n",
    "    Integer(2, 15, name='fwd'),\n",
    "    Real(0.5, 0.9, prior='uniform', name='threshold'),\n",
    "    Categorical([None, 'balanced'], name='class_weight'),\n",
    "    Categorical([True, False], name='drag'),\n",
    "]\n",
    "\n",
    "# search_space = [\n",
    "#     Integer(1,5, name='asd'),\n",
    "#     Categorical(['a','b'], name='letter')\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@use_named_args(search_space)\n",
    "def cv_round(**opt_sets):\n",
    "    \n",
    "    val_scores = []\n",
    "    models = []\n",
    "\n",
    "    cv_periods = {\n",
    "        'sub_start': pd.to_datetime('2002-07-01'),\n",
    "        'sub_end': pd.to_datetime('2005-07-01'),\n",
    "        'val_start': pd.to_datetime('2005-08-01'),\n",
    "        'val_end': pd.to_datetime('2006-01-01'),\n",
    "#         'test_start': pd.to_datetime('2006-02-01'),\n",
    "#         'test_end':pd.to_datetime('2006-07-01')\n",
    "    }\n",
    "    \n",
    "    settings = {\n",
    "        'genmodel': LGBMClassifier,\n",
    "        'verbose': False,\n",
    "#         'force_cw': False, \n",
    "        'model_settings': {\n",
    "            'boosting_type': 'gbdt',\n",
    "            'num_leaves': 31,\n",
    "            'max_depth': -1,\n",
    "            'learning_rate': 0.1,\n",
    "            'n_estimators': 100,\n",
    "            'subsample_for_bin': 200000,\n",
    "            'objective': None,\n",
    "            'class_weight': None, #'balanced'\n",
    "            'min_split_gain': 0.0,\n",
    "            'min_child_weight': 0.001,\n",
    "            'min_child_samples': 20,\n",
    "            'subsample': 1.0,\n",
    "            'subsample_freq': 1,\n",
    "            'colsample_bytree': 1.0,\n",
    "            'reg_alpha': 0.0,\n",
    "            'reg_lambda': 0.0,\n",
    "            'importance_type': 'split'\n",
    "        },\n",
    "        'preproc_mkt': {\n",
    "            'price_lags': [1,5,20,250], \n",
    "            'vol_lags': [2,10]\n",
    "        },\n",
    "        'preproc_tick': {\n",
    "            'fwd': 10,\n",
    "            'cut_first': 150, \n",
    "            'price_lags': [1,2,5,10,20,50,100,250], \n",
    "            'vol_lags': [2,5,10,20]\n",
    "        }, \n",
    "        'threshold': 0.5,\n",
    "        'drag': False\n",
    "    }\n",
    "    \n",
    "    if opt_sets != None:\n",
    "        \n",
    "        if ('boosting_type' in opt_sets.keys()) and (opt_sets['boosting_type'] == 'goss') and \\\n",
    "            ('subsample' in opt_sets.keys()):\n",
    "            del opt_sets['subsample']\n",
    "            \n",
    "        \n",
    "        for k, v in opt_sets.items():\n",
    "            \n",
    "            if k in settings.keys():\n",
    "                settings[k] = v\n",
    "            elif k in settings['preproc_tick'].keys():\n",
    "                settings['preproc_tick'][k] = v\n",
    "            else:\n",
    "                settings['model_settings'][k] = v\n",
    "\n",
    "    \n",
    "    while cv_periods['val_end'] < split:\n",
    "        try:\n",
    "            valdf, _, = cv_step(train_df, train_market, cv_periods, settings)\n",
    "            val_scores.append(valdf)\n",
    "        except:\n",
    "            print(opt_sets)\n",
    "            raise Exception(\"Error\")\n",
    "        cv_periods = shift_cv(cv_periods, drag=settings['drag'])\n",
    "    \n",
    "    score = -prod_return(pd.concat(val_scores), sharpe=False)/settings['preproc_tick']['fwd']\n",
    "    #print(score)\n",
    "    \n",
    "    myfile = open('working.txt', 'w')\n",
    "    myfile.write(str(-score) + '\\n' + str(settings) + '\\n\\n' + datetime.now().strftime(\"%H:%M:%S\"))\n",
    "    myfile.close()\n",
    "    \n",
    "    if np.isnan(score):\n",
    "        return 0\n",
    "    else:\n",
    "        return score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7351270834059807, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7351270834059807\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7351270834059807, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7351270834059807\n",
      "{'boosting_type': 'rf', 'num_leaves': 3820, 'learning_rate': 0.0002789357895948863, 'n_estimators': 999, 'subsample': 0.24349199820550438, 'min_child_weight': 0.0023930913450846, 'min_child_samples': 391, 'feature_fraction': 0.7351270834059807, 'fwd': 14, 'threshold': 0.8385243666744069, 'class_weight': None, 'drag': True}\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'val2'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3824\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3825\u001b[0;31m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3826\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'val2'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-49d856ab2fc4>\u001b[0m in \u001b[0;36mcv_round\u001b[0;34m(**opt_sets)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mvaldf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_market\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv_periods\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m             \u001b[0mval_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvaldf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-5ac4ea84026e>\u001b[0m in \u001b[0;36mcv_step\u001b[0;34m(train_df, train_market, cv_periods, settings)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mcheck_cv_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_periods\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'verbose'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_tvt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_market\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv_periods\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-073d49ca0447>\u001b[0m in \u001b[0;36mprepare_tvt\u001b[0;34m(train_df, train_market, cv_periods, settings, state_size)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtick\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msub_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtick\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreproc_tick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtick\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarket_sub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarket_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'preproc_tick'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m             val[tick] = preproc_tick(tick, val_df, market_val, market_cols, \\\n",
      "\u001b[0;32m<ipython-input-7-d05a291647ed>\u001b[0m in \u001b[0;36mpreproc_tick\u001b[0;34m(tick, fulldf, market_df, market_cols, fwd, cut_first, price_lags, vol_lags)\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0midf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vol'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vol'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrolling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0midf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrolling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0midf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rel_val'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'relvol'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrolling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3162\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3163\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3239\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3240\u001b[0;31m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3827\u001b[0m             \u001b[0;31m# This item wasn't present, just insert at end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3828\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3829\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, loc, item, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0;31m# insert to the axis; this could possibly raise a TypeError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1197\u001b[0;31m         \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, loc, item)\u001b[0m\n\u001b[1;32m   5563\u001b[0m         \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5564\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, data, dtype, copy, name, tupleize_cols, **kwargs)\u001b[0m\n\u001b[1;32m    359\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m                     return cls(\n\u001b[0m\u001b[1;32m    361\u001b[0m                         \u001b[0mnew_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, data, dtype, copy, name, tupleize_cols, **kwargs)\u001b[0m\n\u001b[1;32m    346\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mFloat64Index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m             \u001b[0;32melif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_bool_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m                 \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"object\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_bool_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m   1391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCIndexClass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/dtypes/generic.py\u001b[0m in \u001b[0;36m_check\u001b[0;34m(cls, inst)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minst\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_typ\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcomp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-8e1b5698fd5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgp_minimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_round\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/skopt/optimizer/gp.py\u001b[0m in \u001b[0;36mgp_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs, model_queue_size)\u001b[0m\n\u001b[1;32m    257\u001b[0m             noise=noise)\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m     return base_minimize(\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0macq_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0macq_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/skopt/optimizer/base.py\u001b[0m in \u001b[0;36mbase_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs, model_queue_size)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_calls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0mnext_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m         \u001b[0mnext_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/skopt/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0;31m# Call the wrapped objective function with the named arguments.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mobjective_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0marg_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobjective_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-49d856ab2fc4>\u001b[0m in \u001b[0;36mcv_round\u001b[0;34m(**opt_sets)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt_sets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0mcv_periods\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshift_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_periods\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'drag'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Error"
     ]
    }
   ],
   "source": [
    "result = gp_minimize(cv_round, search_space, random_state=1, n_calls=10, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = [\n",
    "    \n",
    "    Categorical(['gbdt', 'dart', 'goss', 'rf'], name='boosting_type'),\n",
    "    Integer(2, 4096, name='num_leaves'),\n",
    "    Real(0.0001, 0.3, prior='log-uniform', name='learning_rate'),\n",
    "    Integer(2, 1000, name='n_estimators'),\n",
    "    Real(0.01, 0.999, name='subsample'),\n",
    "    Real(0.0001, 0.3, prior='log-uniform', name='min_child_weight'),\n",
    "    Integer(5, 1000, name='min_child_samples'),\n",
    "    Real(0.2, 0.999, prior='uniform', name='feature_fraction'),\n",
    "    Integer(2, 15, name='fwd'),\n",
    "    Real(0.5, 0.85, prior='uniform', name='threshold'),\n",
    "    Categorical([None, 'balanced'], name='class_weight'),\n",
    "    Categorical([True, False], name='drag'),\n",
    "]\n",
    "\n",
    "opt_sets = {}\n",
    "x = 0\n",
    "\n",
    "for opt in result.x:\n",
    "    opt_sets[search_space[x].name] = opt\n",
    "    x+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_periods = {\n",
    "    'sub_start': pd.to_datetime('2013-12-01'),\n",
    "    'sub_end': pd.to_datetime('2016-12-01'),\n",
    "    'val_start': pd.to_datetime('2017-01-01'),\n",
    "    'val_end': pd.to_datetime('2017-04-01'),\n",
    "#         'test_start': pd.to_datetime('2006-02-01'),\n",
    "#         'test_end':pd.to_datetime('2006-07-01')\n",
    "}\n",
    "\n",
    "settings = {\n",
    "    'genmodel': LGBMClassifier,\n",
    "    'verbose': True,\n",
    "#         'force_cw': False, \n",
    "    'model_settings': {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': 31,\n",
    "        'max_depth': -1,\n",
    "        'learning_rate': 0.1,\n",
    "        'n_estimators': 100,\n",
    "        'subsample_for_bin': 200000,\n",
    "        'objective': None,\n",
    "        'class_weight': None, #'balanced'\n",
    "        'min_split_gain': 0.0,\n",
    "        'min_child_weight': 0.001,\n",
    "        'min_child_samples': 20,\n",
    "        'subsample': 1.0,\n",
    "        'subsample_freq': 1,\n",
    "        'colsample_bytree': 1.0,\n",
    "        'reg_alpha': 0.0,\n",
    "        'reg_lambda': 0.0,\n",
    "        'importance_type': 'split'\n",
    "    },\n",
    "    'preproc_mkt': {\n",
    "        'price_lags': [1,5,20,250], \n",
    "        'vol_lags': [2,10]\n",
    "    },\n",
    "    'preproc_tick': {\n",
    "        'fwd': 10,\n",
    "        'cut_first': 150, \n",
    "        'price_lags': [1,2,5,10,20,50,100,250], \n",
    "        'vol_lags': [2,5,10,20]\n",
    "    }, \n",
    "    'threshold': 0.5,\n",
    "    'drag': False\n",
    "}\n",
    "\n",
    "if ('boosting_type' in opt_sets.keys()) and (opt_sets['boosting_type'] == 'goss') and \\\n",
    "    ('subsample' in opt_sets.keys()):\n",
    "    del opt_sets['subsample']\n",
    "\n",
    "for k, v in opt_sets.items():\n",
    "            \n",
    "    if k in settings.keys():\n",
    "        settings[k] = v\n",
    "    elif k in settings['preproc_tick'].keys():\n",
    "        settings['preproc_tick'][k] = v\n",
    "    else:\n",
    "        settings['model_settings'][k] = v\n",
    "\n",
    "val_dfs = []\n",
    "\n",
    "while cv_periods['val_end'] < test_df['aa'].index[-1]:\n",
    "    \n",
    "    cv_periods = shift_cv(cv_periods, shift=3, drag=True)\n",
    "    #print(cv_periods['val_end'])\n",
    "    val, _ = cv_step(test_df, test_market, cv_periods, settings=settings)\n",
    "    val_dfs.append(val)\n",
    "\n",
    "#prod_return(val, penalize=False, sharpe=False, compress=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_return(pd.concat(val_dfs), penalize=False, sharpe=False, compress=None, com=0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(val_dfs)\n",
    "print(df[df.predy == 1].shape)\n",
    "df[df.predy == 1]['fwd'].hist(bins=40, figsize=[15,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m47",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m47"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
