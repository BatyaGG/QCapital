{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import random\n",
    "import math\n",
    "import pickle\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Integer, Real, Categorical\n",
    "from skopt.utils import use_named_args\n",
    "from scipy.stats.mstats import gmean\n",
    "from sklearn.metrics import matthews_corrcoef as matt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "close = pd.read_parquet('rus_close_201120.parquet').iloc[:,:1000]\n",
    "volume = pd.read_parquet('rus_volume_201120.parquet').iloc[:,:1000]\n",
    "\n",
    "market = pd.read_excel(\"market.xlsx\", index_col='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from backtester import Portfolio, Calc_invest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_start(date):\n",
    "    \"\"\"\n",
    "    Makes the model aware of current date\n",
    "    \"\"\"\n",
    "    if date.year % 4 == 0:\n",
    "        base = 366\n",
    "    else:\n",
    "        base = 365\n",
    "        \n",
    "    ystart = pd.to_datetime(str(date.year) + '-01-01')\n",
    "    return (date - ystart).days / base\n",
    "\n",
    "\n",
    "def get_tick_df(x, split=pd.to_datetime('2017-01-01')):\n",
    "    \"\"\"\n",
    "    Combines information for a ticker from 'close' and 'volume' dataframes into one,\n",
    "    Calculates 'valtr' column - 'value traded',\n",
    "    Splits data into master 'train' and 'test' parts\n",
    "    \n",
    "    x - column index for the respective column date\n",
    "    split - date to split into 'test' and 'train' parts\n",
    "    \"\"\"\n",
    "    tick_df = close.iloc[:,x:x+2]\n",
    "    tick = tick_df.columns[1]\n",
    "    tick_df['volume'] = volume[tick]\n",
    "    tick_df.columns = ['date', tick, 'volume']\n",
    "    tick_df = tick_df.set_index('date').dropna()\n",
    "    tick_df['valtr'] = tick_df[tick] * tick_df['volume'] / 1000000\n",
    "    train = tick_df.loc[:split]\n",
    "    test = tick_df.copy()\n",
    "    \n",
    "    return train, test\n",
    "\n",
    "market['dt'] = market.index\n",
    "market['dt'] = market['dt'].apply(year_start)\n",
    "market['spyval'] = market['spy'] * market['spyv'] / 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6109b5e3543849e9bd2ad90998c89713",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Timestamp('2016-12-30 00:00:00'), Timestamp('2002-01-02 00:00:00'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 0\n",
    "\n",
    "train_df = {}\n",
    "test_df = {}\n",
    "split = pd.to_datetime('2017-01-01')\n",
    "\n",
    "for _ in tqdm_notebook(range(int(close.shape[1]/2))):\n",
    "    \n",
    "    tick = close.iloc[:,x+1].name\n",
    "    if close[tick].dropna().shape[0] == 0:\n",
    "        # some are empty, these are ignored\n",
    "        x+=2\n",
    "        continue\n",
    "    else:\n",
    "        train_df[tick], test_df[tick] = get_tick_df(x, split=split)\n",
    "        x+=2\n",
    "\n",
    "train_market = market.loc[:split]\n",
    "test_market = market.copy()\n",
    "\n",
    "train_market.index[-1], test_market.index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_cv_error(cv_periods, verbose=True):\n",
    "    \"\"\"\n",
    "    Checks for look-ahead biases and other errors in cv periods,\n",
    "    reports data if required so or if silent - raises exceptions\n",
    "    \"\"\"\n",
    "    sub_start = cv_periods['sub_start']\n",
    "    sub_end = cv_periods['sub_end']\n",
    "    val_start = cv_periods['val_start']\n",
    "    val_end = cv_periods['val_end']\n",
    "#     test_start = cv_periods['test_start']\n",
    "#     test_end = cv_periods['test_end']\n",
    "    \n",
    "    if verbose:\n",
    "        if sub_start > sub_end:\n",
    "            print(\"Training sample dates error\")\n",
    "\n",
    "        if sub_end > val_start:\n",
    "            print(\"Validation starts before training ends!\")\n",
    "\n",
    "        if val_start > val_end:\n",
    "            print(\"Validation sample dates error\")\n",
    "        print(\"Training starts at\", sub_start, \"Training sample size is\", (sub_end - sub_start).days, \n",
    "              \"\\nValidation starts at\", val_start, \"Validation sample size is\", (val_end - val_start).days,\n",
    "              \"\\nNumber of days purged between training and validation is\", (val_start - sub_end).days)\n",
    "    \n",
    "    else:\n",
    "        if sub_start > sub_end:\n",
    "            raise Exception(\"Training sample dates error\")\n",
    "\n",
    "        if sub_end > val_start:\n",
    "            raise Exception(\"Validation starts before training ends!\")\n",
    "\n",
    "        if val_start > val_end:\n",
    "            raise Exception(\"Validation sample dates error\")\n",
    "        \n",
    "    pass\n",
    "\n",
    "def shift_cv(cv_periods, shift=12, drag=False):\n",
    "    \"\"\"\n",
    "    Shifts cross-validation periods by a set number of months\n",
    "    \"\"\" \n",
    "    \n",
    "    new_periods = {}\n",
    "    for k, v in cv_periods.items():\n",
    "        if (k == 'sub_start') and (drag == False):\n",
    "            new_periods[k] = v\n",
    "        else:\n",
    "            new_periods[k] = (v + np.timedelta64(shift, 'M')).round('d')\n",
    "    \n",
    "    return new_periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_to_one(series, log=True):\n",
    "    \"\"\"\n",
    "    Scales data from 0 to 1 while not looking ahead because of cummin/cummax methods.\n",
    "    If log=True, first takes np.log of the series\n",
    "    \"\"\"\n",
    "    if log:\n",
    "        return (np.log(series) - np.log(series).cummin()) / (np.log(series).cummax() - np.log(series).cummin() )\n",
    "    else:\n",
    "        return (series - series.cummin()) / (series.cummax() - series.cummin() )\n",
    "    \n",
    "def prod_return(valdf, compress=0.5, sharpe=False, com=0.002, penalize=0.1):\n",
    "    \n",
    "    if 'predy' not in valdf.columns:\n",
    "        print(\"No 'predy' column found!\")\n",
    "        return 0\n",
    "    elif 'fwd' not in valdf.columns:\n",
    "        print(\"No 'fwd' column found!\")\n",
    "        return 0\n",
    "    elif (compress != None) and ( compress <= 0):\n",
    "        print(\"'compress' input must be >0!\")\n",
    "        return 0\n",
    "    \n",
    "    else:\n",
    "        if compress != None:\n",
    "            valdf['fwd'] = np.where( valdf['fwd'] > 0.5, 0.5, valdf['fwd'] )\n",
    "        \n",
    "        valdf['pred_return'] = 1 + valdf['predy'] * (valdf['fwd'] - com)\n",
    "        \n",
    "        if valdf.predy.sum() >= 1:\n",
    "            prod_return = valdf['pred_return'].prod()**(1.0/len(valdf[valdf.predy == 1])) - 1\n",
    "        else:\n",
    "            return -valdf.testy.mean()\n",
    "        \n",
    "        if penalize:\n",
    "            if 'testy' not in valdf.columns:\n",
    "                print(\"No 'testy' column found!\")\n",
    "                return 0\n",
    "            \n",
    "            ratio = valdf['predy'].mean()/valdf['testy'].mean()\n",
    "            if ratio < penalize:\n",
    "                prod_return = prod_return * ratio / penalize\n",
    "        \n",
    "        if sharpe:\n",
    "            \n",
    "            return (prod_return / valdf[valdf.predy == 1]['fwd'].std())\n",
    "            \n",
    "        else:\n",
    "            return prod_return\n",
    "\n",
    "def preproc_mkt(mkt_df, price_lags=[1,5,20,250], vol_lags=[2,10]):\n",
    "    \n",
    "    \"\"\"\n",
    "    Prepares data for market dataframe. \n",
    "    Creates delta features for every price_lags unit for spy price, 10year rate, 3month rate and oil price.\n",
    "    Creates rolling average features for 1 and every vol_lags unit for vix, dollar index and spy volume. \n",
    "    \n",
    "    returns clean market dataframe and columns of the dataframe\n",
    "    Attention! returing dataframe contains a non-feature column 'spyv', used for further relative feature creation \n",
    "    \"\"\"\n",
    "    \n",
    "    for lag in price_lags:\n",
    "        ret_name = 'spy' + str(lag)\n",
    "        mkt_df[ret_name] = mkt_df['spy']/mkt_df['spy'].shift(lag)-1\n",
    "        mkt_df[ret_name] = zero_to_one(mkt_df[ret_name], log=False)\n",
    "\n",
    "        ret_name = '10y' + str(lag)\n",
    "        mkt_df[ret_name] = mkt_df['rate10y']/mkt_df['rate10y'].shift(lag)-1\n",
    "        mkt_df[ret_name] = zero_to_one(mkt_df[ret_name], log=False)\n",
    "\n",
    "        ret_name = '3m' + str(lag)\n",
    "        mkt_df[ret_name] = mkt_df['rate3m']/mkt_df['rate3m'].shift(lag)-1\n",
    "        mkt_df[ret_name] = zero_to_one(mkt_df[ret_name], log=False)\n",
    "\n",
    "        ret_name = 'oil' + str(lag)\n",
    "        mkt_df[ret_name] = mkt_df['oil']/mkt_df['oil'].shift(lag)-1\n",
    "        mkt_df[ret_name] = zero_to_one(mkt_df[ret_name], log=False)\n",
    "\n",
    "\n",
    "    mkt_df['spyvol'] = zero_to_one(mkt_df['spyv'], log=True)\n",
    "    \n",
    "    mkt_df['dxy'] = zero_to_one(mkt_df['dxy'], log=False)\n",
    "    \n",
    "    mkt_df['s_vix'] = zero_to_one(mkt_df['vix'], log=True)\n",
    "\n",
    "    for lag in vol_lags:\n",
    "        mkt_df['spyvol' + str(lag)] = mkt_df['spyvol'].rolling(lag).mean()\n",
    "        mkt_df['dxy' + str(lag)] = mkt_df['dxy'].rolling(lag).mean()\n",
    "        mkt_df['s_vix' + str(lag)] = mkt_df['s_vix'].rolling(lag).mean()\n",
    "\n",
    "    junk_cols = ['vix', 'spy', 'spyv', 'rate10y', 'rate3m', 'oil']\n",
    "\n",
    "    mkt_df = mkt_df.drop(columns=junk_cols)\n",
    "    return mkt_df, mkt_df.columns\n",
    "\n",
    "def preproc_tick(tick, fulldf, market_df, market_cols, fwd=5, \n",
    "                 cut_first=150, price_lags=[1,2,5,10,20,50,100,250], vol_lags=[2,5,10,20]):\n",
    "    \"\"\"\n",
    "    Prepares data for a ticker dataframe. \n",
    "    Creates delta features for every price_lags unit for close price.\n",
    "    Creates rolling average features for 1 and every vol_lags unit for volatility and value traded. \n",
    "    Cuts first 150 days, because they are too noisy usually due to cummax/cummin methods\n",
    "    \n",
    "    Parameters:\n",
    "        tick - ticker used\n",
    "        fulldf - dictionary with all tickers that is limited by cv_periods\n",
    "        market_df - output of preproc_mkt function\n",
    "        market_cols - output of preproc_mkt function\n",
    "        fwd - forecasting period in days\n",
    "    \n",
    "    returns clean ticker dataframe \n",
    "    \"\"\"\n",
    "    \n",
    "    idf = fulldf[tick]\n",
    "    idf['fwd'] = idf[tick].shift(-fwd) / idf[tick] - 1\n",
    "    \n",
    "    fwd_tr = 0.141986 * np.sqrt(fwd/252)\n",
    "    \n",
    "    idf['ycol'] = np.where( idf['fwd'] >= fwd_tr, 1, 0 )\n",
    "    \n",
    "    idf[market_cols] = market_df\n",
    "    \n",
    "    for lag in price_lags:\n",
    "        ret_name = 'ret' + str(lag)\n",
    "        idf[ret_name] = idf[tick]/idf[tick].shift(lag)-1\n",
    "        idf[ret_name] = zero_to_one(idf[ret_name], log=False)\n",
    "\n",
    "    idf['relvol'] = np.log(idf['valtr']) / np.log(idf['spyval'])\n",
    "    idf['vol'] = zero_to_one(idf['volume'], log=True)\n",
    "    idf['val'] = zero_to_one(idf['valtr'], log=True)\n",
    "\n",
    "    for lag in vol_lags:\n",
    "        idf['vol' + str(lag)] = idf['vol'].rolling(lag).mean()\n",
    "        idf['val' + str(lag)] = idf['val'].rolling(lag).mean()\n",
    "        idf['rel_val' + str(lag)] = idf['relvol'].rolling(lag).mean()\n",
    "    \n",
    "    idf['tick'] = tick\n",
    "    idf['vlt'] = idf['ret1'].std() #Volatility\n",
    "    \n",
    "    junk_cols = [tick, 'volume', 'valtr', 'spyval']\n",
    "    return idf.drop(columns=junk_cols).iloc[cut_first:].dropna()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StepCV():\n",
    "    \n",
    "    def __init__(self, full_data=None, full_market=None, cv_periods=None, proc_data_func=None, \n",
    "                 proc_mkt_func=None, settings=None):\n",
    "        \n",
    "        self.full_data = full_data\n",
    "        self.full_market = full_market\n",
    "        self.cv_periods = cv_periods\n",
    "        self.settings = settings\n",
    "        self.proc_data_func = proc_data_func\n",
    "        self.proc_mkt_func = proc_mkt_func\n",
    "        \n",
    "        if self.settings == None:\n",
    "            self.genmodel = LGBMClassifier\n",
    "            check_cv_error(self.cv_periods, verbose=False)\n",
    "            self.split()\n",
    "            self.preproc_data()\n",
    "            self.model = self.genmodel(random_state=1, n_jobs=-1)\n",
    "            \n",
    "        else:\n",
    "            self.genmodel = self.settings['genmodel']\n",
    "            check_cv_error(cv_periods, verbose=self.settings['verbose'])\n",
    "            self.split()\n",
    "            self.preproc_data()\n",
    "            self.model = self.genmodel(random_state=1, n_jobs=-1, **settings['model_settings'])\n",
    "            \n",
    "        self.train_X = self.train.drop(columns = ['ycol', 'fwd', 'vlt'])\n",
    "        self.train_y = self.train['ycol']\n",
    "        val_X = self.val.drop(columns = ['ycol', 'fwd', 'vlt'])\n",
    "        val_y = self.val['ycol']\n",
    "        \n",
    "        try:\n",
    "            self.model.fit(self.train_X, self.train_y)\n",
    "        except:\n",
    "            raise Exception('Error')\n",
    "        \n",
    "        if self.settings == None:\n",
    "            val_X['proby'] = self.model.predict_proba(val_X)[:,1]\n",
    "            val_X['predy'] = np.where(val_X['proby'] > 0.5, 1, 0)\n",
    "        else:\n",
    "            val_X['proby'] = self.model.predict_proba(val_X)[:,1]\n",
    "            val_X['predy'] = np.where(val_X['proby'] > settings['threshold'], 1, 0)\n",
    "            \n",
    "        val_X['fwd'] = self.val['fwd']\n",
    "        val_X['testy'] = val_y\n",
    "        self.val_X = val_X\n",
    "        self.valx = self.val_X[['testy','predy','proby','fwd']]\n",
    "        self.val_score = prod_return(self.valx.copy())\n",
    "        self.matt_score = matt( self.valx['testy'], self.valx['predy'] )\n",
    "    \n",
    "    def split(self):\n",
    "        \n",
    "        self.sub_df = {}\n",
    "        self.val_df = {}\n",
    "\n",
    "        for k, v in self.full_data.items():\n",
    "\n",
    "            self.sub_df[k] = v.loc[self.cv_periods['sub_start']:self.cv_periods['sub_end']]\n",
    "            self.val_df[k] = v.loc[self.cv_periods['sub_start']:self.cv_periods['val_end']]\n",
    "\n",
    "        self.market_sub = self.full_market.loc[self.cv_periods['sub_start']:self.cv_periods['sub_end']].copy()\n",
    "        self.market_val = self.full_market.loc[self.cv_periods['sub_start']:self.cv_periods['val_end']].copy()\n",
    "        \n",
    "    def preproc_data(self):\n",
    "        \n",
    "        self.train = {}\n",
    "        self.val = {}\n",
    "        self.vols = {}\n",
    "        \n",
    "        if self.settings == None:\n",
    "            self.market_sub, _ = self.proc_mkt_func(self.market_sub)\n",
    "            self.market_val, self.market_cols = self.proc_mkt_func(self.market_val)\n",
    "            \n",
    "            for tick in tqdm_notebook(self.sub_df.copy().keys()):\n",
    "                self.train[tick] = self.proc_data_func(tick, self.sub_df, self.market_sub, self.market_cols)\n",
    "                self.val[tick] = self.proc_data_func(tick, self.val_df, self.market_val, \n",
    "                                                     self.market_cols).loc[self.cv_periods['val_start']:]\n",
    "        \n",
    "        else:\n",
    "            self.market_sub, _ = self.proc_mkt_func(self.market_sub, **self.settings['preproc_mkt'])\n",
    "            self.market_val, self.market_cols = self.proc_mkt_func(self.market_val, **self.settings['preproc_mkt'])\n",
    "            \n",
    "            for tick in self.sub_df.copy().keys():\n",
    "                self.train[tick] = self.proc_data_func(tick, self.sub_df, self.market_sub, \n",
    "                                                       self.market_cols, **self.settings['preproc_tick'])\n",
    "                try:\n",
    "                    self.vols[tick] = self.train[tick]['vlt'].iloc[-1]\n",
    "                except:\n",
    "                    self.vols[tick] = 0\n",
    "                self.val[tick] = self.proc_data_func(tick, self.val_df, self.market_val, self.market_cols, \n",
    "                                                     **self.settings['preproc_tick']).loc[self.cv_periods['val_start']:]\n",
    "        \n",
    "        nlargest = int(len(self.sub_df.keys())*self.settings['top_vol'])\n",
    "        self.vols = pd.Series(self.vols).nlargest(nlargest)\n",
    "        self.train = {c: self.train[c] for c in self.vols.index}\n",
    "        self.val = {c: self.val[c] for c in self.vols.index}             \n",
    "        \n",
    "        self.train = pd.concat( self.train.values() ).sort_index()\n",
    "        self.train['tick date'] = self.train.index.astype(str) + ':' + self.train['tick']\n",
    "        self.train = self.train.set_index('tick date').drop(columns=['tick'])\n",
    "\n",
    "        self.val = pd.concat( self.val.values() ).sort_index()\n",
    "        self.val['tick date'] = self.val.index.astype(str) + ':' + self.val['tick']\n",
    "        self.val = self.val.set_index('tick date').drop(columns=['tick'])\n",
    "        \n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {\n",
    "    'genmodel': LGBMClassifier, \n",
    "    'verbose': False, \n",
    "    'model_settings': {\n",
    "        'boosting_type': 'gbdt', \n",
    "        'num_leaves': 2663, \n",
    "        'max_depth': -1, \n",
    "        'learning_rate': 0.08882030882895775, \n",
    "        'n_estimators': 844, \n",
    "        'subsample_for_bin': 200000, \n",
    "        'objective': None, \n",
    "        'class_weight': None, \n",
    "        'min_split_gain': 0.0, \n",
    "        'min_child_weight': 0.00034988764861549547, \n",
    "        'min_child_samples': 732, \n",
    "        'subsample': 0.670359813425697, \n",
    "        'subsample_freq': 1, \n",
    "#         'colsample_bytree': 1.0, \n",
    "        'reg_alpha': 0.0, \n",
    "        'reg_lambda': 0.0, \n",
    "        'importance_type': 'split', \n",
    "        'colsample_bytree': 0.599917250527772}, \n",
    "    'preproc_mkt': {'price_lags': [1, 5, 20, 250], 'vol_lags': [2, 10]}, \n",
    "    'preproc_tick': {\n",
    "        'fwd': 8, \n",
    "        'cut_first': 150, 'price_lags': [1, 2, 5, 10, 20, 50, 100, 250], 'vol_lags': [2, 5, 10, 20]}, \n",
    "    'threshold': 0.7554631330855286, \n",
    "    'top_vol': 0.6940517879788671, \n",
    "    'drag': False}\n",
    "\n",
    "cv_periods = {\n",
    "        'sub_start': pd.to_datetime('2002-07-01'),\n",
    "        'sub_end': pd.to_datetime('2005-07-01'),\n",
    "        'val_start': pd.to_datetime('2005-08-01'),\n",
    "        'val_end': pd.to_datetime('2006-01-01')\n",
    "    }\n",
    "\n",
    "prep = StepCV(full_data=train_df, \n",
    "                  full_market=train_market, \n",
    "                  cv_periods=cv_periods, \n",
    "                  proc_data_func=preproc_tick, \n",
    "                  proc_mkt_func=preproc_mkt,\n",
    "                  settings=settings\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "773b07d3e2a34f0ca5b8e9b538f6cac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=94), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spx</th>\n",
       "      <th>inXdays</th>\n",
       "      <th>portfolio</th>\n",
       "      <th>part</th>\n",
       "      <th>part1</th>\n",
       "      <th>part2</th>\n",
       "      <th>part3</th>\n",
       "      <th>part4</th>\n",
       "      <th>part5</th>\n",
       "      <th>part6</th>\n",
       "      <th>part7</th>\n",
       "      <th>part8</th>\n",
       "      <th>chosen</th>\n",
       "      <th>spx100</th>\n",
       "      <th>p100</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2005-08-08</td>\n",
       "      <td>1223.13</td>\n",
       "      <td>1219.02</td>\n",
       "      <td>200000.00</td>\n",
       "      <td>1</td>\n",
       "      <td>25000.00</td>\n",
       "      <td>25000.00</td>\n",
       "      <td>25000.00</td>\n",
       "      <td>25000.00</td>\n",
       "      <td>25000.00</td>\n",
       "      <td>25000.00</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>25000.00</td>\n",
       "      <td>['bmy']</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2005-08-09</td>\n",
       "      <td>1231.38</td>\n",
       "      <td>1219.71</td>\n",
       "      <td>200000.00</td>\n",
       "      <td>2</td>\n",
       "      <td>25000.00</td>\n",
       "      <td>25000.00</td>\n",
       "      <td>25000.00</td>\n",
       "      <td>25000.00</td>\n",
       "      <td>25000.00</td>\n",
       "      <td>25000.00</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>25000.00</td>\n",
       "      <td>['all']</td>\n",
       "      <td>100.674499</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2005-08-10</td>\n",
       "      <td>1229.13</td>\n",
       "      <td>1221.73</td>\n",
       "      <td>200000.00</td>\n",
       "      <td>3</td>\n",
       "      <td>25000.00</td>\n",
       "      <td>25000.00</td>\n",
       "      <td>25000.00</td>\n",
       "      <td>25000.00</td>\n",
       "      <td>25000.00</td>\n",
       "      <td>25000.00</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>25000.00</td>\n",
       "      <td>['fmc']</td>\n",
       "      <td>100.490545</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2005-08-11</td>\n",
       "      <td>1237.81</td>\n",
       "      <td>1217.57</td>\n",
       "      <td>200000.00</td>\n",
       "      <td>4</td>\n",
       "      <td>25000.00</td>\n",
       "      <td>25000.00</td>\n",
       "      <td>25000.00</td>\n",
       "      <td>25000.00</td>\n",
       "      <td>25000.00</td>\n",
       "      <td>25000.00</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>25000.00</td>\n",
       "      <td>['isrg']</td>\n",
       "      <td>101.200199</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2005-08-12</td>\n",
       "      <td>1230.39</td>\n",
       "      <td>1209.59</td>\n",
       "      <td>200000.00</td>\n",
       "      <td>5</td>\n",
       "      <td>25000.00</td>\n",
       "      <td>25000.00</td>\n",
       "      <td>25000.00</td>\n",
       "      <td>25000.00</td>\n",
       "      <td>25000.00</td>\n",
       "      <td>25000.00</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>25000.00</td>\n",
       "      <td>['isrg']</td>\n",
       "      <td>100.593559</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2005-12-13</td>\n",
       "      <td>1267.43</td>\n",
       "      <td>1259.92</td>\n",
       "      <td>224175.15</td>\n",
       "      <td>2</td>\n",
       "      <td>22346.17</td>\n",
       "      <td>26742.02</td>\n",
       "      <td>28922.59</td>\n",
       "      <td>31705.32</td>\n",
       "      <td>31714.86</td>\n",
       "      <td>31999.46</td>\n",
       "      <td>23190.6</td>\n",
       "      <td>27554.13</td>\n",
       "      <td>spx</td>\n",
       "      <td>103.621855</td>\n",
       "      <td>112.087575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2005-12-14</td>\n",
       "      <td>1272.74</td>\n",
       "      <td>1259.92</td>\n",
       "      <td>224343.67</td>\n",
       "      <td>3</td>\n",
       "      <td>22346.17</td>\n",
       "      <td>26742.02</td>\n",
       "      <td>29091.11</td>\n",
       "      <td>31705.32</td>\n",
       "      <td>31714.86</td>\n",
       "      <td>31999.46</td>\n",
       "      <td>23190.6</td>\n",
       "      <td>27554.13</td>\n",
       "      <td>spx</td>\n",
       "      <td>104.055988</td>\n",
       "      <td>112.171835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2005-12-15</td>\n",
       "      <td>1270.94</td>\n",
       "      <td>1259.92</td>\n",
       "      <td>224564.92</td>\n",
       "      <td>4</td>\n",
       "      <td>22346.17</td>\n",
       "      <td>26742.02</td>\n",
       "      <td>29091.11</td>\n",
       "      <td>31926.57</td>\n",
       "      <td>31714.86</td>\n",
       "      <td>31999.46</td>\n",
       "      <td>23190.6</td>\n",
       "      <td>27554.13</td>\n",
       "      <td>['amt']</td>\n",
       "      <td>103.908824</td>\n",
       "      <td>112.282460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2005-12-16</td>\n",
       "      <td>1267.32</td>\n",
       "      <td>1259.92</td>\n",
       "      <td>223946.80</td>\n",
       "      <td>5</td>\n",
       "      <td>22346.17</td>\n",
       "      <td>26742.02</td>\n",
       "      <td>29091.11</td>\n",
       "      <td>31926.57</td>\n",
       "      <td>31096.74</td>\n",
       "      <td>31999.46</td>\n",
       "      <td>23190.6</td>\n",
       "      <td>27554.13</td>\n",
       "      <td>['eog']</td>\n",
       "      <td>103.612862</td>\n",
       "      <td>111.973400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2005-12-19</td>\n",
       "      <td>1259.92</td>\n",
       "      <td>1259.92</td>\n",
       "      <td>224228.34</td>\n",
       "      <td>6</td>\n",
       "      <td>22346.17</td>\n",
       "      <td>26742.02</td>\n",
       "      <td>29091.11</td>\n",
       "      <td>31926.57</td>\n",
       "      <td>31096.74</td>\n",
       "      <td>32281.00</td>\n",
       "      <td>23190.6</td>\n",
       "      <td>27554.13</td>\n",
       "      <td>['amt']</td>\n",
       "      <td>103.007857</td>\n",
       "      <td>112.114170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                spx  inXdays  portfolio  part     part1     part2     part3  \\\n",
       "date                                                                          \n",
       "2005-08-08  1223.13  1219.02  200000.00     1  25000.00  25000.00  25000.00   \n",
       "2005-08-09  1231.38  1219.71  200000.00     2  25000.00  25000.00  25000.00   \n",
       "2005-08-10  1229.13  1221.73  200000.00     3  25000.00  25000.00  25000.00   \n",
       "2005-08-11  1237.81  1217.57  200000.00     4  25000.00  25000.00  25000.00   \n",
       "2005-08-12  1230.39  1209.59  200000.00     5  25000.00  25000.00  25000.00   \n",
       "...             ...      ...        ...   ...       ...       ...       ...   \n",
       "2005-12-13  1267.43  1259.92  224175.15     2  22346.17  26742.02  28922.59   \n",
       "2005-12-14  1272.74  1259.92  224343.67     3  22346.17  26742.02  29091.11   \n",
       "2005-12-15  1270.94  1259.92  224564.92     4  22346.17  26742.02  29091.11   \n",
       "2005-12-16  1267.32  1259.92  223946.80     5  22346.17  26742.02  29091.11   \n",
       "2005-12-19  1259.92  1259.92  224228.34     6  22346.17  26742.02  29091.11   \n",
       "\n",
       "               part4     part5     part6    part7     part8    chosen  \\\n",
       "date                                                                    \n",
       "2005-08-08  25000.00  25000.00  25000.00  25000.0  25000.00   ['bmy']   \n",
       "2005-08-09  25000.00  25000.00  25000.00  25000.0  25000.00   ['all']   \n",
       "2005-08-10  25000.00  25000.00  25000.00  25000.0  25000.00   ['fmc']   \n",
       "2005-08-11  25000.00  25000.00  25000.00  25000.0  25000.00  ['isrg']   \n",
       "2005-08-12  25000.00  25000.00  25000.00  25000.0  25000.00  ['isrg']   \n",
       "...              ...       ...       ...      ...       ...       ...   \n",
       "2005-12-13  31705.32  31714.86  31999.46  23190.6  27554.13       spx   \n",
       "2005-12-14  31705.32  31714.86  31999.46  23190.6  27554.13       spx   \n",
       "2005-12-15  31926.57  31714.86  31999.46  23190.6  27554.13   ['amt']   \n",
       "2005-12-16  31926.57  31096.74  31999.46  23190.6  27554.13   ['eog']   \n",
       "2005-12-19  31926.57  31096.74  32281.00  23190.6  27554.13   ['amt']   \n",
       "\n",
       "                spx100        p100  \n",
       "date                                \n",
       "2005-08-08  100.000000  100.000000  \n",
       "2005-08-09  100.674499  100.000000  \n",
       "2005-08-10  100.490545  100.000000  \n",
       "2005-08-11  101.200199  100.000000  \n",
       "2005-08-12  100.593559  100.000000  \n",
       "...                ...         ...  \n",
       "2005-12-13  103.621855  112.087575  \n",
       "2005-12-14  104.055988  112.171835  \n",
       "2005-12-15  103.908824  112.282460  \n",
       "2005-12-16  103.612862  111.973400  \n",
       "2005-12-19  103.007857  112.114170  \n",
       "\n",
       "[94 rows x 15 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_inv = Calc_invest(fwd=settings['preproc_tick']['fwd'])\n",
    "portf = Portfolio(prep.valx['proby'], train_df, days_shift=settings['preproc_tick']['fwd'], \n",
    "                      threshold=settings['threshold'], calc_invest=calc_inv)\n",
    "portf.portf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6210d3e5e3074ac8b932f332d2f37e3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=94), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.08683619980953124 0.01577198947397518 \n",
      " spx100    103.007857\n",
      "p100      112.114170\n",
      "Name: 2005-12-19 00:00:00, dtype: float64 2006-01-01 00:00:00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d6c5617d445494fa8009d1929ec19f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=83), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.018659410840884554 0.000712875424545834 \n",
      " spx100    111.095410\n",
      "p100      112.717995\n",
      "Name: 2006-12-07 00:00:00, dtype: float64 2007-01-01 00:00:00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee3cb8aa14cd4428a71c6701ce44f423",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=98), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.027324552716074486 0.0055063367822394405 \n",
      " spx100     99.261159\n",
      "p100      120.911795\n",
      "Name: 2007-12-18 00:00:00, dtype: float64 2008-01-01 00:00:00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1392b816c3e94ae3b6b08e60ab14474f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=99), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.13827117974924627 -0.002102890563888238 \n",
      " spx100    69.851189\n",
      "p100      58.375585\n",
      "Name: 2008-12-18 00:00:00, dtype: float64 2008-12-31 00:00:00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89abd929f7e94e4e9294d0e24914dc71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=77), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.006435418823848173 0.00046473343123025924 \n",
      " spx100    112.267666\n",
      "p100      114.337980\n",
      "Name: 2009-12-03 00:00:00, dtype: float64 2009-12-31 00:00:00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ba074a5a46244068ee7624f29907c72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=99), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.03556921684599532 0.006595689231006149 \n",
      " spx100    110.766880\n",
      "p100      120.698905\n",
      "Name: 2010-12-20 00:00:00, dtype: float64 2010-12-31 00:00:00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb69be4215a043eb9c61311199925681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=97), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.011017265401223327 0.0005576413200168455 \n",
      " spx100    95.636892\n",
      "p100      89.997135\n",
      "Name: 2011-12-19 00:00:00, dtype: float64 2011-12-31 00:00:00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f28b27bae6e400aa86c0324d3a166d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=92), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.013948785965334293 0.0004935950960588839 \n",
      " spx100    102.400202\n",
      "p100      105.959815\n",
      "Name: 2012-12-10 00:00:00, dtype: float64 2012-12-30 00:00:00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c67c2f3f86a4ce9aa26ae2d8841d48c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=92), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.03216661907984389 0.004402162048000461 \n",
      " spx100    104.920235\n",
      "p100      124.040210\n",
      "Name: 2013-12-17 00:00:00, dtype: float64 2013-12-30 00:00:00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2f9ff055b994916bfa7b20f4daa0282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=99), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.22859364705596638 0.038753547882319106 \n",
      " spx100    102.173527\n",
      "p100       99.683020\n",
      "Name: 2014-12-17 00:00:00, dtype: float64 2014-12-30 00:00:00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c40def790cc47339ccdd73a0a6b6dba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=96), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.09104012497050509 0.022137699839269276 \n",
      " spx100    97.543137\n",
      "p100      91.304350\n",
      "Name: 2015-12-17 00:00:00, dtype: float64 2015-12-30 00:00:00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fad3ab6a9f3742209f351ad8c773134b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-0.004594585788264864 -8.704303471631661e-05 \n",
      " spx100    100.020164\n",
      "p100      100.000000\n",
      "Name: 2016-10-14 00:00:00, dtype: float64 2016-12-29 00:00:00\n"
     ]
    }
   ],
   "source": [
    "cv_periods = {\n",
    "        'sub_start': pd.to_datetime('2002-07-01'),\n",
    "        'sub_end': pd.to_datetime('2005-07-01'),\n",
    "        'val_start': pd.to_datetime('2005-08-01'),\n",
    "        'val_end': pd.to_datetime('2006-01-01')\n",
    "    }\n",
    "\n",
    "res = {}\n",
    "\n",
    "while cv_periods['val_end'] <= split:\n",
    "    prep = StepCV(full_data=train_df, \n",
    "                  full_market=train_market, \n",
    "                  cv_periods=cv_periods, \n",
    "                  proc_data_func=preproc_tick, \n",
    "                  proc_mkt_func=preproc_mkt,\n",
    "                  settings=settings\n",
    "        )\n",
    "    \n",
    "    calc_inv = Calc_invest(fwd=settings['preproc_tick']['fwd'])\n",
    "    \n",
    "    if prep.valx['predy'].sum() > 0:\n",
    "        portf = Portfolio(prep.valx['proby'], train_df, days_shift=settings['preproc_tick']['fwd'], \n",
    "                      threshold=settings['threshold'], calc_invest=calc_inv)\n",
    "\n",
    "        print(prep.matt_score, prep.val_score, '\\n', portf.portf_df[['spx100', 'p100']].iloc[-1], cv_periods['val_end'])\n",
    "    else:\n",
    "        \n",
    "        print(prep.matt_score, prep.val_score, [100, 100], cv_periods['val_end'])\n",
    "        \n",
    "    res[cv_periods['val_end']] = prep\n",
    "    \n",
    "    cv_periods = shift_cv(cv_periods, drag=settings['drag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = [\n",
    "    \n",
    "    Categorical(['gbdt', 'dart', 'goss', 'rf'], name='boosting_type'),\n",
    "    Integer(2, 4096, name='num_leaves'),\n",
    "    Real(0.0001, 0.3, prior='log-uniform', name='learning_rate'),\n",
    "    Integer(2, 1000, name='n_estimators'),\n",
    "    Real(0.01, 0.999, name='subsample'),\n",
    "    Real(0.0001, 0.3, prior='log-uniform', name='min_child_weight'),\n",
    "    Integer(5, 1000, name='min_child_samples'),\n",
    "    Real(0.2, 0.999, prior='uniform', name='colsample_bytree'),\n",
    "    Integer(2, 15, name='fwd'),\n",
    "    Real(0.5, 0.9, prior='uniform', name='threshold'),\n",
    "    Categorical([None, 'balanced'], name='class_weight'),\n",
    "    Categorical([True, False], name='drag'),\n",
    "    Real(0.1, 1.0, prior='uniform', name='top_vol'),\n",
    "]\n",
    "\n",
    "@use_named_args(search_space)\n",
    "def cv_round(**opt_sets):\n",
    "\n",
    "    cv_periods = {\n",
    "        'sub_start': pd.to_datetime('2002-07-01'),\n",
    "        'sub_end': pd.to_datetime('2005-12-01'),\n",
    "        'val_start': pd.to_datetime('2006-01-01'),\n",
    "        'val_end': pd.to_datetime('2007-01-01'),\n",
    "    }\n",
    "    \n",
    "    settings = {\n",
    "        'genmodel': LGBMClassifier,\n",
    "        'verbose': False,\n",
    "        'model_settings': {\n",
    "            'boosting_type': 'gbdt',\n",
    "            'num_leaves': 31,\n",
    "            'max_depth': -1,\n",
    "            'learning_rate': 0.1,\n",
    "            'n_estimators': 100,\n",
    "            'subsample_for_bin': 200000,\n",
    "            'objective': None,\n",
    "            'class_weight': None, #'balanced'\n",
    "            'min_split_gain': 0.0,\n",
    "            'min_child_weight': 0.001,\n",
    "            'min_child_samples': 20,\n",
    "            'subsample': 1.0,\n",
    "            'subsample_freq': 1,\n",
    "            'colsample_bytree': 1.0,\n",
    "            'reg_alpha': 0.0,\n",
    "            'reg_lambda': 0.0,\n",
    "            'importance_type': 'split'\n",
    "        },\n",
    "        'preproc_mkt': {\n",
    "            'price_lags': [1,5,20,250], \n",
    "            'vol_lags': [2,10]\n",
    "        },\n",
    "        'preproc_tick': {\n",
    "            'fwd': 10,\n",
    "            'cut_first': 150, \n",
    "            'price_lags': [1,2,5,10,20,50,100,250], \n",
    "            'vol_lags': [2,5,10,20]\n",
    "        }, \n",
    "        'threshold': 0.5,\n",
    "        'top_vol': 0.2, \n",
    "        'drag': False\n",
    "    }\n",
    "    \n",
    "    if opt_sets != None:\n",
    "        \n",
    "        if ('boosting_type' in opt_sets.keys()) and (opt_sets['boosting_type'] == 'goss') and \\\n",
    "            ('subsample' in opt_sets.keys()):\n",
    "            del opt_sets['subsample']\n",
    "            \n",
    "        \n",
    "        for k, v in opt_sets.items():\n",
    "            \n",
    "            if k in settings.keys():\n",
    "                settings[k] = v\n",
    "            elif k in settings['preproc_tick'].keys():\n",
    "                settings['preproc_tick'][k] = v\n",
    "            else:\n",
    "                settings['model_settings'][k] = v\n",
    "    \n",
    "    val_dfs = []\n",
    "    zroz = 0\n",
    "    \n",
    "    while cv_periods['val_end'] <= split:\n",
    "        prep = StepCV(full_data=train_df, \n",
    "                      full_market=train_market, \n",
    "                      cv_periods=cv_periods, \n",
    "                      proc_data_func=preproc_tick, \n",
    "                      proc_mkt_func=preproc_mkt,\n",
    "                      settings=settings\n",
    "            )\n",
    "        \n",
    "        if (prep.valx.predy.sum() == 0):\n",
    "            print(\"Futile, next!\")\n",
    "            myfile = open('results.txt', 'a+')\n",
    "            myfile.write('\\n' + str(-prep.valx.testy.mean()) + '\\n' + str(settings) + \\\n",
    "                         '\\n' + datetime.now().strftime(\"%H:%M:%S\"))\n",
    "            myfile.close()\n",
    "            return prep.valx.testy.mean()\n",
    "        \n",
    "        val_dfs.append(prep.valx)\n",
    "        cv_periods = shift_cv(cv_periods, drag=settings['drag'])\n",
    "\n",
    "#     score = -prod_return(pd.concat(val_dfs))\n",
    "    val_dfs = pd.concat(val_dfs)\n",
    "    score = -matt( val_dfs['testy'], val_dfs['predy'] )\n",
    "    \n",
    "    calc_inv = Calc_invest(fwd=settings['preproc_tick']['fwd'])\n",
    "    portf = Portfolio(val_dfs['proby'], train_df, days_shift=settings['preproc_tick']['fwd'], \n",
    "                      threshold=settings['threshold'], calc_invest=calc_inv)\n",
    "\n",
    "    portf_return = round(portf.portf_df['p100'].iloc[-1],2)\n",
    "    spx_return = round(portf.portf_df['spx100'].iloc[-1],2)\n",
    "    \n",
    "    myfile = open('results.txt', 'a+')\n",
    "    myfile.write('\\nMatt score: ' + str(round(-score, 5)) + '\\tReturn: ' + str(portf_return) + \n",
    "                 '\\tSPX return: ' + str(spx_return) + \n",
    "                 '\\n' + str(settings) + '\\n' + datetime.now().strftime(\"%H:%M:%S\"))\n",
    "    myfile.close()\n",
    "    \n",
    "\n",
    "    if np.isnan(score):\n",
    "        return 0\n",
    "    else:\n",
    "        return score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "myfile = open('results.txt', 'w')\n",
    "myfile.write(\"started\\n\")\n",
    "myfile.close()\n",
    "\n",
    "# result = gp_minimize(cv_round, search_space, random_state=1, n_calls=200, verbose=True, n_initial_points=25)\n",
    "result = gp_minimize(cv_round, search_space, random_state=1, n_calls=30, verbose=True, n_initial_points=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found = {'genmodel': LGBMClassifier,\n",
    " 'verbose': False,\n",
    " 'model_settings': {'boosting_type': 'gbdt',\n",
    "  'num_leaves': 2663,\n",
    "  'max_depth': -1,\n",
    "  'learning_rate': 0.08882030882895775,\n",
    "  'n_estimators': 844,\n",
    "  'subsample_for_bin': 200000,\n",
    "  'objective': None,\n",
    "  'class_weight': None,\n",
    "  'min_split_gain': 0.0,\n",
    "  'min_child_weight': 0.00034988764861549547,\n",
    "  'min_child_samples': 732,\n",
    "  'subsample': 0.670359813425697,\n",
    "  'subsample_freq': 1,\n",
    "  'reg_alpha': 0.0,\n",
    "  'reg_lambda': 0.0,\n",
    "  'importance_type': 'split',\n",
    "  'colsample_bytree': 0.599917250527772},\n",
    " 'preproc_mkt': {'price_lags': [1, 5, 20, 250], 'vol_lags': [2, 10]},\n",
    " 'preproc_tick': {'fwd': 8,\n",
    "  'cut_first': 150,\n",
    "  'price_lags': [1, 2, 5, 10, 20, 50, 100, 250],\n",
    "  'vol_lags': [2, 5, 10, 20]},\n",
    " 'threshold': 0.7554631330855286,\n",
    " 'top_vol': 0.6940517879788671,\n",
    " 'drag': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = [\n",
    "    \n",
    "    Categorical(['gbdt', 'dart', 'goss', 'rf'], name='boosting_type'),\n",
    "    Integer(2, 4096, name='num_leaves'),\n",
    "    Real(0.0001, 0.3, prior='log-uniform', name='learning_rate'),\n",
    "    Integer(2, 1000, name='n_estimators'),\n",
    "    Real(0.01, 0.999, name='subsample'),\n",
    "    Real(0.0001, 0.3, prior='log-uniform', name='min_child_weight'),\n",
    "    Integer(5, 1000, name='min_child_samples'),\n",
    "    Real(0.2, 0.999, prior='uniform', name='colsample_bytree'),\n",
    "    Integer(2, 15, name='fwd'),\n",
    "    Real(0.5, 0.9, prior='uniform', name='threshold'),\n",
    "    Categorical([None, 'balanced'], name='class_weight'),\n",
    "    Categorical([True, False], name='drag'),\n",
    "    Real(0.1, 1.0, prior='uniform', name='top_vol'),\n",
    "]\n",
    "\n",
    "opt_sets = {}\n",
    "x = 0\n",
    "\n",
    "for opt in result.x:\n",
    "    opt_sets[search_space[x].name] = opt\n",
    "    x+=1\n",
    "    \n",
    "\n",
    "cv_periods = {\n",
    "    'sub_start': pd.to_datetime('2013-12-01'),\n",
    "    'sub_end': pd.to_datetime('2016-12-01'),\n",
    "    'val_start': pd.to_datetime('2017-01-01'),\n",
    "    'val_end': pd.to_datetime('2017-04-01'),\n",
    "}\n",
    "\n",
    "settings = {\n",
    "        'genmodel': LGBMClassifier,\n",
    "        'verbose': False,\n",
    "        'model_settings': {\n",
    "            'boosting_type': 'gbdt',\n",
    "            'num_leaves': 31,\n",
    "            'max_depth': -1,\n",
    "            'learning_rate': 0.1,\n",
    "            'n_estimators': 100,\n",
    "            'subsample_for_bin': 200000,\n",
    "            'objective': None,\n",
    "            'class_weight': None, #'balanced'\n",
    "            'min_split_gain': 0.0,\n",
    "            'min_child_weight': 0.001,\n",
    "            'min_child_samples': 20,\n",
    "            'subsample': 1.0,\n",
    "            'subsample_freq': 1,\n",
    "            'colsample_bytree': 1.0,\n",
    "            'reg_alpha': 0.0,\n",
    "            'reg_lambda': 0.0,\n",
    "            'importance_type': 'split'\n",
    "        },\n",
    "        'preproc_mkt': {\n",
    "            'price_lags': [1,5,20,250], \n",
    "            'vol_lags': [2,10]\n",
    "        },\n",
    "        'preproc_tick': {\n",
    "            'fwd': 10,\n",
    "            'cut_first': 150, \n",
    "            'price_lags': [1,2,5,10,20,50,100,250], \n",
    "            'vol_lags': [2,5,10,20]\n",
    "        }, \n",
    "        'threshold': 0.5,\n",
    "        'top_vol': 0.2, \n",
    "        'drag': False\n",
    "    }\n",
    "    \n",
    "if opt_sets != None:\n",
    "\n",
    "    if ('boosting_type' in opt_sets.keys()) and (opt_sets['boosting_type'] == 'goss') and \\\n",
    "        ('subsample' in opt_sets.keys()):\n",
    "        del opt_sets['subsample']\n",
    "\n",
    "\n",
    "    for k, v in opt_sets.items():\n",
    "\n",
    "        if k in settings.keys():\n",
    "            settings[k] = v\n",
    "        elif k in settings['preproc_tick'].keys():\n",
    "            settings['preproc_tick'][k] = v\n",
    "        else:\n",
    "            settings['model_settings'][k] = v\n",
    "\n",
    "val_dfs = []\n",
    "\n",
    "while cv_periods['val_end'] < test_df['aa'].index[-1]:\n",
    "    prep = StepCV(full_data=test_df, \n",
    "                  full_market=test_market, \n",
    "                  cv_periods=cv_periods, \n",
    "                  proc_data_func=preproc_tick, \n",
    "                  proc_mkt_func=preproc_mkt,\n",
    "                  settings=settings\n",
    "        )\n",
    "\n",
    "    val_dfs.append(prep.valx)\n",
    "    print(\"Calculated until\", cv_periods['val_end'], \"Local valscore is\", round(prep.val_score*100,2),\n",
    "         \"Local genscore is\", round( gmean(prep.valx.fwd + 1)*100 - 100, 2 ))\n",
    "    cv_periods = shift_cv(cv_periods, drag=settings['drag'], shift=3)\n",
    "\n",
    "score = prod_return(pd.concat(val_dfs))\n",
    "print(\"Testing score\", round(score*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_inv = Calc_invest(fwd=settings['preproc_tick']['fwd'])\n",
    "portf = Portfolio(pd.concat(val_dfs)['proby'], test_df, days_shift=settings['preproc_tick']['fwd'], \n",
    "                      threshold=settings['threshold'], calc_invest=calc_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portf.portf_df[['spx100', 'p100']].plot(figsize=[16,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m47",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m47"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
